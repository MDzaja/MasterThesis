{
  "num_transformer_blocks": 1,
  "head_size": 256,
  "num_heads": 2,
  "ff_dim": 2,
  "transformer_dropout": 0.0,
  "num_mlp_layers": 3,
  "mlp_units_0": 512,
  "mlp_dropout": 0.5,
  "learning_rate": 0.0001,
  "decay_steps": 10000,
  "decay_rate": 0.8,
  "mlp_units_1": 32,
  "mlp_units_2": 32,
  "mlp_units_3": 32
}